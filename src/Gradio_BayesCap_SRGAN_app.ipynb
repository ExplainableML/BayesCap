{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c688bbe5-1f70-4fd6-b984-df85e960a096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 1547350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uupa90/anaconda3/envs/pytorch1.11/lib/python3.10/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7897/\n",
      "Running on public URL: https://57702.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://57702.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f452057f940>,\n",
       " 'http://127.0.0.1:7897/',\n",
       " 'https://57702.gradio.app')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import InterpolationMode as IMode\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from ds import *\n",
    "from losses import *\n",
    "from networks_SRGAN import *\n",
    "from utils import *\n",
    "\n",
    "\n",
    "NetG = Generator()\n",
    "model_parameters = filter(lambda p: True, NetG.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print(\"Number of Parameters:\",params)\n",
    "NetC = BayesCap(in_channels=3, out_channels=3)\n",
    "\n",
    "\n",
    "NetG = Generator()\n",
    "NetG.load_state_dict(torch.load('../ckpt/srgan-ImageNet-bc347d67.pth', map_location='cuda:0'))\n",
    "NetG.to('cuda')\n",
    "NetG.eval()\n",
    "\n",
    "NetC = BayesCap(in_channels=3, out_channels=3)\n",
    "NetC.load_state_dict(torch.load('../ckpt/BayesCap_SRGAN_best.pth', map_location='cuda:0'))\n",
    "NetC.to('cuda')\n",
    "NetC.eval()\n",
    "\n",
    "def tensor01_to_pil(xt):\n",
    "    r = transforms.ToPILImage(mode='RGB')(xt.squeeze())\n",
    "    return r\n",
    "\n",
    "\n",
    "def predict(img):\n",
    "    \"\"\"\n",
    "    img: image\n",
    "    \"\"\"\n",
    "    image_size = (256,256)\n",
    "    upscale_factor = 4\n",
    "    lr_transforms = transforms.Resize((image_size[0]//upscale_factor, image_size[1]//upscale_factor), interpolation=IMode.BICUBIC, antialias=True)\n",
    "    # lr_transforms = transforms.Resize((128, 128), interpolation=IMode.BICUBIC, antialias=True)\n",
    "    \n",
    "    img = Image.fromarray(np.array(img))\n",
    "    img = lr_transforms(img)\n",
    "    lr_tensor = utils.image2tensor(img, range_norm=False, half=False)\n",
    "    \n",
    "    device = 'cuda'\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    xLR = lr_tensor.to(device).unsqueeze(0)\n",
    "    xLR = xLR.type(dtype)\n",
    "    # pass them through the network\n",
    "    with torch.no_grad():\n",
    "        xSR = NetG(xLR)\n",
    "        xSRC_mu, xSRC_alpha, xSRC_beta = NetC(xSR)\n",
    "        \n",
    "    a_map = (1/(xSRC_alpha[0] + 1e-5)).to('cpu').data\n",
    "    b_map = xSRC_beta[0].to('cpu').data\n",
    "    u_map = (a_map**2)*(torch.exp(torch.lgamma(3/(b_map + 1e-2)))/torch.exp(torch.lgamma(1/(b_map + 1e-2)))) \n",
    "    \n",
    "    \n",
    "    x_LR = tensor01_to_pil(xLR.to('cpu').data.clip(0,1).transpose(0,2).transpose(0,1))\n",
    "    \n",
    "    x_mean = tensor01_to_pil(xSR.to('cpu').data.clip(0,1).transpose(0,2).transpose(0,1))\n",
    "    \n",
    "    #im = Image.fromarray(np.uint8(cm.gist_earth(myarray)*255))\n",
    "    \n",
    "    a_map = torch.clamp(a_map, min=0, max=0.1)\n",
    "    a_map = (a_map - a_map.min())/(a_map.max() - a_map.min())\n",
    "    x_alpha = Image.fromarray(np.uint8(cm.inferno(a_map.transpose(0,2).transpose(0,1).squeeze())*255))\n",
    "    \n",
    "    b_map = torch.clamp(b_map, min=0.45, max=0.75)\n",
    "    b_map = (b_map - b_map.min())/(b_map.max() - b_map.min())\n",
    "    x_beta = Image.fromarray(np.uint8(cm.cividis(b_map.transpose(0,2).transpose(0,1).squeeze())*255))\n",
    "    \n",
    "    u_map = torch.clamp(u_map, min=0, max=0.15)\n",
    "    u_map = (u_map - u_map.min())/(u_map.max() - u_map.min())\n",
    "    x_uncer = Image.fromarray(np.uint8(cm.hot(u_map.transpose(0,2).transpose(0,1).squeeze())*255))\n",
    "    \n",
    "    return x_LR, x_mean, x_alpha, x_beta, x_uncer\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "title = \"BayesCap\"\n",
    "description = \"BayesCap: Bayesian Identity Cap for Calibrated Uncertainty in Frozen Neural Networks (ECCV 2022)\"\n",
    "article = \"<p style='text-align: center'> BayesCap: Bayesian Identity Cap for Calibrated Uncertainty in Frozen Neural Networks| <a href='https://github.com/ExplainableML/BayesCap'>Github Repo</a></p>\"\n",
    "\n",
    "\n",
    "gr.Interface(\n",
    "    fn=predict, \n",
    "    inputs=gr.inputs.Image(type='pil', label=\"Orignal\"), \n",
    "    outputs=[\n",
    "        gr.outputs.Image(type='pil', label=\"Low-res\"), \n",
    "        gr.outputs.Image(type='pil', label=\"Super-res\"), \n",
    "        gr.outputs.Image(type='pil', label=\"Alpha\"), \n",
    "        gr.outputs.Image(type='pil', label=\"Beta\"), \n",
    "        gr.outputs.Image(type='pil', label=\"Uncertainty\")\n",
    "     ],\n",
    "    title=title,\n",
    "    description=description,\n",
    "    article=article,\n",
    "     examples=[\n",
    "        [\"../../../BayesCap/data/SR/val/Set5/original/baby.png\"],\n",
    "        [\"../../../BayesCap/data/SR/val/Set5/original/bird.png\"]\n",
    "    ]\n",
    ").launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
